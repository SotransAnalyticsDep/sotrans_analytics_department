{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'source.common'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mloguru\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[32m     10\u001b[39m sys.path.append(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDesktop\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mgithub\u001b[39m\u001b[33m\\\u001b[39m\u001b[33msotrans_analytics_department\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexcel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m error_xl_shared_strings_xml\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengineering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CheckExistsDataInTable\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'source.common'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "sys.path.append(r'C:\\Users\\user\\Desktop\\github\\sotrans_analytics_department')\n",
    "from source.common.exceptions.excel import error_xl_shared_strings_xml\n",
    "from source.engineering.validation import CheckExistsDataInTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'C:\\Users\\user\\YandexDisk\\batch_movement\\01.02.2024.xlsx'\n",
    "report_date = filepath.rsplit(sep='\\\\', maxsplit=1)[-1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.remove()\n",
    "logger.add(sink=sys.stderr, level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sa.create_engine(\"postgresql+psycopg2://postgres:30691@localhost:5432/one_c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS: list[str] = [\n",
    "    # Склады (wh -> warehouse)\n",
    "    'wh_id_1c',\n",
    "    'wh_name_1c',\n",
    "    \n",
    "    # Документ движения (dm -> document movement)\n",
    "    'dm_date',\n",
    "    'dm_id_1c',\n",
    "    'dm_org',\n",
    "    'dm_dep',\n",
    "    'dm_type',\n",
    "    \n",
    "    # Документ партии (db -> document batch)\n",
    "    'db_date',\n",
    "    'db_id_1c',\n",
    "    'db_org',\n",
    "    'db_dep',\n",
    "    'db_type',\n",
    "    \n",
    "    # Контрагент (ca -> contragent)\n",
    "    'ca_id_1c',\n",
    "    'ca_name_1c',\n",
    "    \n",
    "    # Номенклатура (sku -> ???)\n",
    "    'sku_id_1c',\n",
    "    \n",
    "    # Начальный остаток (stb -> start balance)\n",
    "    'stb_sku_sc_rub',\n",
    "    'stb_cnt',\n",
    "    'stb_sum_sc_rub',\n",
    "    'stb_sum_sc_euro',\n",
    "    \n",
    "    # Приход (inb -> income balance)\n",
    "    'inb_sku_sc_rub',\n",
    "    'inb_cnt',\n",
    "    'inb_sum_sc_rub',\n",
    "    'inb_sum_sc_euro',\n",
    "    \n",
    "    # Расход (exb -> expend balance)\n",
    "    'exb_sku_sc_rub',\n",
    "    'exb_cnt',\n",
    "    'exb_sum_sc_rub',\n",
    "    'exb_sum_sc_euro',\n",
    "    \n",
    "    # Конечный остаток (enb -> end balance)\n",
    "    'enb_sku_sc_rub',\n",
    "    'enb_cnt',\n",
    "    'enb_sum_sc_rub',\n",
    "    'enb_sum_sc_euro',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_DATA: str = '_нет данных'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOCAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filldown_in_dm(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбцах \"dm_date\", \"dm_id_1c\", \"dm_org\", \"dm_dep\", и \"dm_type\" методом \"вниз\"')\n",
    "    df.loc[:, 'dm_date'] = df['dm_date'].ffill()\n",
    "    df.loc[:, 'dm_id_1c'] = df['dm_id_1c'].ffill()\n",
    "    df.loc[:, 'dm_org'] = df['dm_org'].ffill()\n",
    "    df.loc[:, 'dm_dep'] = df['dm_dep'].ffill()\n",
    "    df.loc[:, 'dm_type'] = df['dm_type'].ffill()\n",
    "    logger.success('Пропуски в столбцах \"dm_date\", \"dm_id_1c\", \"dm_org\", \"dm_dep\", и \"dm_type\" успешно заполнены методом \"вниз\"')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filldown_in_db(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбцах \"db_date\", \"db_id_1c\", \"db_org\", \"db_dep\", и \"db_type\" методом \"вниз\"')\n",
    "    df.loc[:, 'db_date'] = df['db_date'].ffill()\n",
    "    df.loc[:, 'db_id_1c'] = df['db_id_1c'].ffill()\n",
    "    df.loc[:, 'db_org'] = df['db_org'].ffill()\n",
    "    df.loc[:, 'db_dep'] = df['db_dep'].ffill()\n",
    "    df.loc[:, 'db_type'] = df['db_type'].ffill()\n",
    "    logger.success('Пропуски в столбцах \"db_date\", \"db_id_1c\", \"db_org\", \"db_dep\", и \"db_type\" успешно заполнены методом \"вниз\"')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filldown_in_ca(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбцах \"ca_id_1c\", \"ca_name_1c\" методом \"вниз\"')\n",
    "    df.loc[:, 'ca_id_1c'] = df['ca_id_1c'].ffill()\n",
    "    df.loc[:, 'ca_name_1c'] = df['ca_name_1c'].ffill()\n",
    "    logger.success('Пропуски в столбцах \"ca_id_1c\", \"ca_name_1c\" успешно заполнены методом \"вниз\"')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropna_in_sku_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Удаление пропусков в столбце \"sku_id_1c\"')\n",
    "    df = df.dropna(subset='sku_id_1c')\n",
    "    logger.success('Пропуски в столбце \"sku_id_1c\" успешно удалены')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOURCE FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка наличия данных в базе за отчётную дату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckExistsDataInTable().batch_movement_by_date(report_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@error_xl_shared_strings_xml\n",
    "def create_dataframe(filepath: str) -> pd.DataFrame:\n",
    "    logger.debug('Старт формирования датафрейма')\n",
    "    df: pd.DataFrame = pd.read_excel(\n",
    "        io=filepath,\n",
    "        engine='openpyxl',\n",
    "        skiprows=6,\n",
    "        skipfooter=1,\n",
    "        usecols=range(6, 37),\n",
    "        names=HEADERS,\n",
    "        dtype='str'\n",
    "    )\n",
    "    logger.success('Датафрейм успешно сформирован')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_report_date_column(df: pd.DataFrame, report_date: str | dt.datetime) -> pd.DataFrame:\n",
    "    logger.debug('Старт добавления столбца с датой отчёта')\n",
    "    df.loc[:, 'date'] = dt.datetime.strptime(report_date, '%d.%m.%Y')\n",
    "    logger.success('Столбец с датой отчёта успешно добавлен')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_report_day_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.loc[:, 'day'] = [date.day for date in df['date']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_report_week_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.loc[:, 'week'] = [date.week for date in df['date']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_report_month_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.loc[:, 'month'] = [date.month for date in df['date']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_report_quarter_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.loc[:, 'quarter'] = [date.quarter for date in df['date']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_report_year_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.loc[:, 'year'] = [date.year for date in df['date']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_miss_val_in_ca_name(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"ca_name\"')\n",
    "    df.loc[:, 'ca_name_1c'] = [\n",
    "        NO_DATA\n",
    "        if all([str(x) == 'nan' for x in (ca_name, sku_id)])\n",
    "        else ca_name\n",
    "        for ca_name, sku_id in zip(\n",
    "            df.loc[:, 'ca_name_1c'],\n",
    "            df.loc[:, 'sku_id_1c']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"ca_name\" успешно заполнены')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_miss_val_in_ca_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"ca_id_1c\"')\n",
    "    df.loc[:, 'ca_id_1c'] = [\n",
    "        NO_DATA\n",
    "        if ca_name == NO_DATA\n",
    "        else ca_id\n",
    "        for ca_name, ca_id in zip(\n",
    "            df.loc[:, 'ca_name_1c'],\n",
    "            df.loc[:, 'ca_id_1c']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"ca_id_1c\" успешно заполнены')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_miss_val_in_db_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"db_type\"')\n",
    "    df.loc[:, 'db_type'] = [\n",
    "        NO_DATA\n",
    "        if str(db_type).lower() == 'nan' and ca_id == NO_DATA\n",
    "        else db_type\n",
    "        for db_type, ca_id in zip(\n",
    "            df.loc[:, 'db_type'],\n",
    "            df.loc[:, 'ca_id_1c']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"db_type\" успешно заполнены')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_miss_val_in_db_dep(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"db_dep\"')\n",
    "    df.loc[:, 'db_dep'] = [\n",
    "        NO_DATA\n",
    "        if str(db_dep).lower() == 'nan' and ca_id == NO_DATA\n",
    "        else db_dep\n",
    "        for db_dep, ca_id in zip(\n",
    "            df.loc[:, 'db_dep'],\n",
    "            df.loc[:, 'ca_id_1c']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"db_dep\" успешно заполнены')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_miss_val_in_db_org(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"db_org\"')\n",
    "    df.loc[:, 'db_org'] = [\n",
    "        NO_DATA\n",
    "        if str(db_org).lower() == 'nan' and ca_id == NO_DATA\n",
    "        else db_org\n",
    "        for db_org, ca_id in zip(\n",
    "            df.loc[:, 'db_org'],\n",
    "            df.loc[:, 'ca_id_1c']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"db_org\" успешно заполнены')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_miss_val_in_db_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"db_id_1c\"')\n",
    "    df.loc[:, 'db_id_1c'] = [\n",
    "        NO_DATA\n",
    "        if str(db_id_1c).lower() == 'nan' and ca_id == NO_DATA\n",
    "        else db_id_1c\n",
    "        for db_id_1c, ca_id in zip(\n",
    "            df.loc[:, 'db_id_1c'],\n",
    "            df.loc[:, 'ca_id_1c']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"db_id_1c\" успешно заполнены')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_miss_val_in_db_date(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"db_date\"')\n",
    "    df.loc[:, 'db_date'] = [\n",
    "        NO_DATA\n",
    "        if str(db_date).lower() == 'nan' and ca_id == NO_DATA\n",
    "        else db_date\n",
    "        for db_date, ca_id in zip(\n",
    "            df.loc[:, 'db_date'],\n",
    "            df.loc[:, 'ca_id_1c']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"db_date\" успешно заполнены')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_miss_val_in_dm_dep(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"dm_dep\"')\n",
    "    df.loc[:, 'dm_dep'] = [\n",
    "        NO_DATA\n",
    "        if str(dm_dep).lower() == 'nan' and db_date == NO_DATA\n",
    "        else dm_dep\n",
    "        for dm_dep, db_date in zip(\n",
    "            df.loc[:, 'dm_dep'],\n",
    "            df.loc[:, 'db_date']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"dm_dep\" успешно заполнены')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_miss_val_in_dm_org(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"dm_org\"')\n",
    "    df.loc[:, 'dm_org'] = [\n",
    "        NO_DATA\n",
    "        if str(dm_org).lower() == 'nan' and db_date == NO_DATA\n",
    "        else dm_org\n",
    "        for dm_org, db_date in zip(\n",
    "            df.loc[:, 'dm_org'],\n",
    "            df.loc[:, 'db_date']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"dm_org\" успешно заполнены')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_miss_val_in_dm_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"dm_id_1c\"')\n",
    "    df.loc[:, 'dm_id_1c'] = [\n",
    "        NO_DATA\n",
    "        if str(dm_id_1c).lower() == 'nan' and db_date == NO_DATA\n",
    "        else dm_id_1c\n",
    "        for dm_id_1c, db_date in zip(\n",
    "            df.loc[:, 'dm_id_1c'],\n",
    "            df.loc[:, 'db_date']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"dm_id_1c\" успешно заполнены')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_miss_val_in_dm_date(df: pd.DataFrame,) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков в столбце \"dm_date\"')\n",
    "    df.loc[:, 'dm_date'] = [\n",
    "        date\n",
    "        if str(dm_date).lower() == 'nan' and db_date == NO_DATA\n",
    "        else date\n",
    "        for dm_date, db_date, date in zip(\n",
    "            df.loc[:, 'dm_date'],\n",
    "            df.loc[:, 'db_date'],\n",
    "            df.loc[:, 'date']\n",
    "        )\n",
    "    ]\n",
    "    logger.success('Пропуски в столбце \"dm_date\" успешно заполнены')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filldown_in_wh_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков методом \"вниз\" в столбце \"wh_id_1c\"')\n",
    "    df['wh_id_1c'] = df['wh_id_1c'].ffill()\n",
    "    logger.success('Пропуски в столбце \"wh_id_1c\"успешно заполнены методом \"вниз\"')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filldown_in_wh_name(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.debug('Заполнение пропусков методом \"вниз\" в столбце \"wh_name_1c\"')\n",
    "    df['wh_name_1c'] = df['wh_name_1c'].ffill()\n",
    "    logger.success('Пропуски в столбце \"wh_name_1c\" успешно заполнены методом \"вниз\"')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_digit_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    digit_cols: tuple[str] = (\n",
    "        'stb_sku_sc_rub', 'stb_cnt', 'stb_sum_sc_rub', 'stb_sum_sc_euro',\n",
    "        'inb_sku_sc_rub', 'inb_cnt', 'inb_sum_sc_rub', 'inb_sum_sc_euro',\n",
    "        'exb_sku_sc_rub', 'exb_cnt', 'exb_sum_sc_rub', 'exb_sum_sc_euro',\n",
    "        'enb_sku_sc_rub', 'enb_cnt', 'enb_sum_sc_rub', 'enb_sum_sc_euro'\n",
    "    )\n",
    "    df = df.astype(dtype={x: 'float32' for x in digit_cols})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_lower_case(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for column_name in (\n",
    "        'wh_id_1c',\n",
    "        'wh_name_1c',\n",
    "        'dm_id_1c',\n",
    "        'dm_org',\n",
    "        'dm_dep',\n",
    "        'dm_type',\n",
    "        'db_id_1c',\n",
    "        'db_org',\n",
    "        'db_dep',\n",
    "        'db_type',\n",
    "        'ca_id_1c',\n",
    "        'ca_name_1c',\n",
    "        'sku_id_1c'\n",
    "    ):\n",
    "        df[column_name] = df[column_name].str.lower()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD SOURCE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = (\n",
    "    create_dataframe(filepath=filepath)\n",
    "    .pipe(func=add_report_date_column, report_date=report_date)\n",
    "    .pipe(func=add_report_day_column)\n",
    "    .pipe(func=add_report_week_column)\n",
    "    .pipe(func=add_report_month_column)\n",
    "    .pipe(func=add_report_quarter_column)\n",
    "    .pipe(func=add_report_year_column)\n",
    "    .pipe(func=fill_miss_val_in_ca_name)\n",
    "    .pipe(func=fill_miss_val_in_ca_id)\n",
    "    .pipe(func=fill_miss_val_in_db_type)\n",
    "    .pipe(func=fill_miss_val_in_db_dep)\n",
    "    .pipe(func=fill_miss_val_in_db_org)\n",
    "    .pipe(func=fill_miss_val_in_db_id)\n",
    "    .pipe(func=fill_miss_val_in_db_date)\n",
    "    .pipe(func=fill_miss_val_in_dm_dep)\n",
    "    .pipe(func=fill_miss_val_in_dm_org)\n",
    "    .pipe(func=fill_miss_val_in_dm_id)\n",
    "    .pipe(func=fill_miss_val_in_dm_date)\n",
    "    .pipe(func=filldown_in_wh_id)\n",
    "    .pipe(func=filldown_in_wh_name)\n",
    "    .pipe(func=change_digit_types)\n",
    "    .pipe(func=string_to_lower_case)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTRAL NEW CONSTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Контроль новых складов и магазинов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список уникальных филиалов в файле\n",
    "new_warehouse = dataframe[['wh_id_1c', 'wh_name_1c']].drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка списка уникальных магазинов из базы данных\n",
    "with engine.connect() as connection:\n",
    "    pg_warehouse = pd.read_sql_table(\n",
    "        table_name='warehouse',\n",
    "        con=connection,\n",
    "        schema='constant',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получения списка филиалов, которых нет в базе данных\n",
    "new_warehouse = new_warehouse[~new_warehouse['wh_id_1c'].isin(values=pg_warehouse['wh_id_1c'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка новых филиалов в базу данных\n",
    "with engine.connect() as connection:\n",
    "    new_warehouse.to_sql(\n",
    "        name='warehouse',\n",
    "        con=connection,\n",
    "        schema='constant',\n",
    "        index=False,\n",
    "        chunksize=10_000,\n",
    "        if_exists='append'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Контроль новых контрагентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список уникальных контрагентов в файле\n",
    "new_contragent = dataframe[['ca_id_1c', 'ca_name_1c']].drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка списка уникальных магазинов из базы данных\n",
    "with engine.connect() as connection:\n",
    "    pg_contragent = pd.read_sql_table(\n",
    "        table_name='contragent',\n",
    "        con=connection,\n",
    "        schema='constant',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получения списка филиалов, которых нет в базе данных\n",
    "new_contragent = new_contragent[~new_contragent['ca_id_1c'].isin(values=pg_contragent['ca_id_1c'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка новых филиалов в базу данных\n",
    "with engine.connect() as connection:\n",
    "    new_contragent.to_sql(\n",
    "        name='contragent',\n",
    "        con=connection,\n",
    "        schema='constant',\n",
    "        index=False,\n",
    "        chunksize=10_000,\n",
    "        if_exists='append'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка справочника с наименованиями документов \"хоз. операция\"\n",
    "with engine.connect() as connection:\n",
    "    pg_document_type: pd.DataFrame = pd.read_sql_table(\n",
    "        table_name='document_type',\n",
    "        con=connection,\n",
    "        schema='constant',\n",
    "    )\n",
    "\n",
    "# Уникальные документы в исходном датафрейме\n",
    "unique_src_doc_type = set(dataframe['dm_type'].dropna().unique())\n",
    "\n",
    "# Уникальные документы в базе данных\n",
    "unique_pg_doc_type = set(pg_document_type['doc_type'].unique())\n",
    "\n",
    "# Новые документы для добавления в базу\n",
    "new_doc_type = unique_src_doc_type - unique_pg_doc_type\n",
    "\n",
    "# Создание датафрейма с новыми документамии\n",
    "df_new_doc_type = pd.DataFrame(data=new_doc_type, columns=['doc_type'])\n",
    "\n",
    "# Создание столбца с новыми наименованиями на англ. яз.\n",
    "df_new_doc_type['doc_type_name'] = None\n",
    "\n",
    "# Объединение новых значений с уже существующими\n",
    "pg_document_type = pd.concat([pg_document_type, df_new_doc_type])\n",
    "\n",
    "# Присвоение новых наименований\n",
    "pg_document_type.loc[:, 'doc_type_name'] = [\n",
    "    input(f'Введите новое наименование на англ. яз. для документа: \"{rus_doc_name}\"')\n",
    "    if eng_doc_name == None\n",
    "    else eng_doc_name\n",
    "    for rus_doc_name, eng_doc_name in zip(\n",
    "        pg_document_type['doc_type'],\n",
    "        pg_document_type['doc_type_name']\n",
    "    )\n",
    "]\n",
    "\n",
    "# Формирование словаря для замены наименований документов\n",
    "dict_to_replace = dict(zip(pg_document_type['doc_type'], pg_document_type['doc_type_name']))\n",
    "\n",
    "# Переименование документов\n",
    "dataframe['dm_type'] = dataframe['dm_type'].replace(dict_to_replace)\n",
    "\n",
    "# Сохранение новых документов в базу\n",
    "with engine.connect() as connection:\n",
    "    (\n",
    "        pg_document_type\n",
    "        .to_sql(\n",
    "            name='document_type',\n",
    "            con=connection,\n",
    "            schema='constant',\n",
    "            if_exists='replace',\n",
    "            index=False,\n",
    "            chunksize=10_000\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = dataframe[~dataframe['wh_name_1c'].str.contains('товары в пути', case=False)]\n",
    "df_transfer = dataframe[dataframe['wh_name_1c'].str.contains('товары в пути', case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_miss_val_stb_dm_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.loc[:, 'dm_type'] = 'init'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_stb_cnt_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(subset='stb_cnt')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_stb_cnt_below_zero(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.query('stb_cnt > 0')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fillna_in_stb_digit_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    for column_name in ('stb_sku_sc_rub', 'stb_sum_sc_rub', 'stb_sum_sc_euro'):\n",
    "        df.loc[:, column_name] = df[column_name].fillna(0.0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start_balance: pd.DataFrame = (\n",
    "    df_source\n",
    "    [\n",
    "        ['date', 'day', 'week', 'month', 'quarter', 'year']\n",
    "        + HEADERS[:-16]\n",
    "        + HEADERS[-16:-12]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start_balance = (\n",
    "    df_start_balance\n",
    "    .pipe(func=fill_miss_val_stb_dm_type)\n",
    "    .pipe(func=filldown_in_dm)\n",
    "    .pipe(func=filldown_in_db)\n",
    "    .pipe(func=filldown_in_ca)\n",
    "    .pipe(func=dropna_in_sku_id)\n",
    "    .pipe(func=drop_stb_cnt_nan)\n",
    "    .pipe(func=drop_stb_cnt_below_zero)\n",
    "    .pipe(func=fillna_in_stb_digit_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sku_sc_euro(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['sku_sc_euro'] = [\n",
    "        round(euro / cnt, 2)\n",
    "        for euro, cnt in zip(\n",
    "            df['stb_sum_sc_euro'],\n",
    "            df['stb_cnt']\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start_balance['sku_sc_euro'] = [\n",
    "    round(euro / cnt, 2)\n",
    "    for euro, cnt in zip(\n",
    "        df_start_balance['stb_sum_sc_euro'],\n",
    "        df_start_balance['stb_cnt']\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10366.2 / 104.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    df_start_balance.to_sql(\n",
    "        name='bm_st_init',\n",
    "        con=connection,\n",
    "        schema='report',\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        chunksize=10_000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_miss_val_inb_dm_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.loc[:, 'dm_type'] = 'income_balance'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_inb_cnt_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(subset='inb_cnt')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_inb_cnt_below_zero(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.query('inb_cnt > 0')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fillna_in_inb_digit_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    for column_name in ('inb_sku_sc_rub', 'inb_sum_sc_rub', 'inb_sum_sc_euro'):\n",
    "        df.loc[:, column_name] = df[column_name].fillna(0.0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income_balance: pd.DataFrame = (\n",
    "    df_source\n",
    "    [\n",
    "        ['date', 'day', 'week', 'month', 'quarter', 'year']\n",
    "        + HEADERS[:-16]\n",
    "        + HEADERS[-12:-8]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income_balance = (\n",
    "    df_income_balance\n",
    "    .pipe(func=filldown_in_dm)\n",
    "    .pipe(func=filldown_in_db)\n",
    "    .pipe(func=filldown_in_ca)\n",
    "    .pipe(func=dropna_in_sku_id)\n",
    "    .pipe(func=drop_inb_cnt_nan)\n",
    "    .pipe(func=drop_inb_cnt_below_zero)\n",
    "    .pipe(func=fillna_in_inb_digit_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение данных в базу\n",
    "for doc_type in df_income_balance['dm_type'].unique():\n",
    "    with engine.connect() as connection:\n",
    "        (\n",
    "            df_income_balance[df_income_balance['dm_type'] == doc_type]\n",
    "            .to_sql(\n",
    "                name=f'bm_in_{doc_type}',\n",
    "                con=connection,\n",
    "                schema='report',\n",
    "                if_exists='append',\n",
    "                index=False,\n",
    "                chunksize=10_000\n",
    "            )\n",
    "        )\n",
    "        print(f'Документ: \"{doc_type}\" сохранён')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expend Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_miss_val_exb_dm_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.loc[:, 'dm_type'] = 'expend'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_exb_cnt_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(subset='exb_cnt')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_exb_cnt_below_zero(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.query('exb_cnt > 0')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fillna_in_exb_digit_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    for column_name in ('exb_sku_sc_rub', 'exb_sum_sc_rub', 'exb_sum_sc_euro'):\n",
    "        df.loc[:, column_name] = df[column_name].fillna(0.0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expend_balance: pd.DataFrame = (\n",
    "    df_source\n",
    "    [\n",
    "        ['date', 'day', 'week', 'month', 'quarter', 'year']\n",
    "        + HEADERS[:-16]\n",
    "        + HEADERS[-8:-4]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expend_balance = (\n",
    "    df_expend_balance\n",
    "    .pipe(func=filldown_in_dm)\n",
    "    .pipe(func=filldown_in_db)\n",
    "    .pipe(func=filldown_in_ca)\n",
    "    .pipe(func=dropna_in_sku_id)\n",
    "    .pipe(func=drop_exb_cnt_nan)\n",
    "    .pipe(func=drop_exb_cnt_below_zero)\n",
    "    .pipe(func=fillna_in_exb_digit_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expend_balance['dm_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение данных в базу\n",
    "for doc_type in df_expend_balance['dm_type'].unique():\n",
    "    with engine.connect() as connection:\n",
    "        (\n",
    "            df_expend_balance[df_expend_balance['dm_type'] == doc_type]\n",
    "            .to_sql(\n",
    "                name=f'bm_ex_{doc_type}',\n",
    "                con=connection,\n",
    "                schema='report',\n",
    "                if_exists='append',\n",
    "                index=False,\n",
    "                chunksize=10_000\n",
    "            )\n",
    "        )\n",
    "        print(f'Документ: \"{doc_type}\" сохранён')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_miss_val_enb_dm_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.loc[:, 'dm_type'] = 'final'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_enb_cnt_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(subset='enb_cnt')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_enb_cnt_below_zero(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.query('enb_cnt > 0')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fillna_in_enb_digit_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    for column_name in ('enb_sku_sc_rub', 'enb_sum_sc_rub', 'enb_sum_sc_euro'):\n",
    "        df.loc[:, column_name] = df[column_name].fillna(0.0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_end_balance: pd.DataFrame = (\n",
    "    df_source\n",
    "    [\n",
    "        ['date', 'day', 'week', 'month', 'quarter', 'year']\n",
    "        + HEADERS[:-16]\n",
    "        + HEADERS[-4:]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_end_balance = (\n",
    "    df_end_balance\n",
    "    .pipe(func=fill_miss_val_in_dm_date)\n",
    "    .pipe(func=fill_miss_val_enb_dm_type)\n",
    "    .pipe(func=filldown_in_dm)\n",
    "    .pipe(func=filldown_in_db)\n",
    "    .pipe(func=filldown_in_ca)\n",
    "    .pipe(func=dropna_in_sku_id)\n",
    "    .pipe(func=drop_enb_cnt_nan)\n",
    "    .pipe(func=drop_enb_cnt_below_zero)\n",
    "    .pipe(func=fillna_in_enb_digit_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    df_end_balance.to_sql(\n",
    "        name='bm_en_final',\n",
    "        con=connection,\n",
    "        schema='report',\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        chunksize=10_000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_miss_val_trb_dm_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.loc[:, 'dm_type'] = 'transfer'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_trb_cnt_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(subset='enb_cnt')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_trb_cnt_below_zero(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.query('enb_cnt > 0')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fillna_in_trb_digit_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    for column_name in ('enb_sku_sc_rub', 'enb_sum_sc_rub', 'enb_sum_sc_euro'):\n",
    "        df.loc[:, column_name] = df[column_name].fillna(0.0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rename_digit_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"enb_sku_sc_rub\": \"trb_sku_sc_rub\",\n",
    "            \"enb_cnt\": \"trb_cnt\",\n",
    "            \"enb_sum_sc_rub\": \"trb_sum_sc_rub\",\n",
    "            \"enb_sum_sc_euro\": \"trb_sum_sc_euro\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transfer_balance: pd.DataFrame = (\n",
    "    df_transfer\n",
    "    [\n",
    "        ['date', 'day', 'week', 'month', 'quarter', 'year']\n",
    "        + HEADERS[:-16]\n",
    "        + HEADERS[-4:]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transfer_balance = (\n",
    "    df_transfer_balance\n",
    "    .pipe(func=fill_miss_val_in_dm_date)\n",
    "    .pipe(func=fill_miss_val_trb_dm_type)\n",
    "    .pipe(func=filldown_in_dm)\n",
    "    .pipe(func=filldown_in_db)\n",
    "    .pipe(func=filldown_in_ca)\n",
    "    .pipe(func=dropna_in_sku_id)\n",
    "    .pipe(func=drop_trb_cnt_nan)\n",
    "    .pipe(func=drop_trb_cnt_below_zero)\n",
    "    .pipe(func=fillna_in_trb_digit_cols)\n",
    "    .pipe(func=rename_digit_columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    df_transfer_balance.to_sql(\n",
    "        name='bm_tr_transfer',\n",
    "        con=connection,\n",
    "        schema='report',\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        chunksize=10_000\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
